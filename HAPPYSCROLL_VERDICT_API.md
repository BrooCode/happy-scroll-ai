# HappyScroll Combined Verdict API

## üéØ Overview

The **Combined Verdict API** is a powerful endpoint that provides comprehensive video safety analysis by combining two moderation checks in a single request:

1. **Transcript Analysis** - Analyzes video captions/transcript using Gemini AI
2. **Thumbnail Moderation** - Analyzes video thumbnail using Google Cloud Vision

This endpoint is specifically designed for parental control applications and browser extensions that need complete video safety assessment.

---

## üìç Endpoint

```
POST /api/happyScroll/v1/verdict
```

---

## üîê Authentication

Currently no authentication required. API uses server-side keys configured in environment variables.

---

## üì• Request Format

### Request Body

```json
{
  "video_url": "https://www.youtube.com/watch?v=VIDEO_ID"
}
```

### Parameters

| Parameter | Type | Required | Description |
|-----------|------|----------|-------------|
| `video_url` | string | Yes | YouTube video URL (supports various formats) |

### Supported URL Formats

```
‚úÖ https://www.youtube.com/watch?v=VIDEO_ID
‚úÖ https://youtu.be/VIDEO_ID
‚úÖ https://www.youtube.com/shorts/VIDEO_ID
‚úÖ https://www.youtube.com/embed/VIDEO_ID
```

---

## üì§ Response Format

### Success Response (200 OK)

```json
{
  "is_safe_transcript": true,
  "is_safe_thumbnail": true,
  "is_safe": true,
  "transcript_reason": "Content is educational and appropriate for children.",
  "thumbnail_reason": "Thumbnail is safe. No inappropriate content detected.",
  "overall_reason": "‚úÖ SAFE: Both transcript and thumbnail are appropriate for children.",
  "video_title": "Educational Kids Video",
  "channel_title": "Kids Learning Channel"
}
```

### Response Fields

| Field | Type | Description |
|-------|------|-------------|
| `is_safe_transcript` | boolean | Whether video transcript/captions are safe |
| `is_safe_thumbnail` | boolean | Whether video thumbnail is safe |
| `is_safe` | boolean | **Overall verdict** (true only if BOTH are safe) |
| `transcript_reason` | string | Detailed reason from transcript analysis |
| `thumbnail_reason` | string | Detailed reason from thumbnail moderation |
| `overall_reason` | string | Combined explanation of verdict |
| `video_title` | string | Video title from YouTube |
| `channel_title` | string | Channel name from YouTube |

---

## üîç Analysis Process

### ‚ö° Parallel Processing (Steps 1 & 2 run simultaneously)

**Step 1: Transcript Analysis** (15-30 seconds)
- Extracts video captions/transcript via YouTube Data API
- Analyzes content with Gemini 2.0 Flash AI
- Applies **12 strict safety rules** (Indian parenting norms)
- Checks for: nudity, violence, racism, adult themes, etc.

**Step 2: Thumbnail Moderation** (2-5 seconds)
- Fetches video thumbnail (maxresdefault or hqdefault)
- Analyzes with Google Cloud Vision SafeSearch
- Checks categories: adult, violence, racy, medical, spoof

> üí° **Performance Boost**: Steps 1 and 2 run in parallel using `asyncio.gather()`, reducing total time by 30-40%!

**Step 3: Combined Verdict** (<1 second)
- **SAFE**: Only if BOTH transcript AND thumbnail are safe
- **UNSAFE**: If EITHER transcript OR thumbnail is flagged
- Provides detailed reasoning for decision

---

## üìä Example Responses

### Example 1: Completely Safe Video

```json
{
  "is_safe_transcript": true,
  "is_safe_thumbnail": true,
  "is_safe": true,
  "transcript_reason": "Content is educational and appropriate for children. No safety concerns detected.",
  "thumbnail_reason": "Thumbnail is safe. No inappropriate content detected.",
  "overall_reason": "‚úÖ SAFE: Both transcript and thumbnail are appropriate for children.",
  "video_title": "Learn Colors with Fun Animations",
  "channel_title": "Kids Educational Channel"
}
```

### Example 2: Unsafe Transcript, Safe Thumbnail

```json
{
  "is_safe_transcript": false,
  "is_safe_thumbnail": true,
  "is_safe": false,
  "transcript_reason": "UNSAFE - Contains adult themes and inappropriate language. Following strict Indian parenting norms, this content is not suitable for children.",
  "thumbnail_reason": "Thumbnail is safe. No inappropriate content detected.",
  "overall_reason": "‚ùå UNSAFE: Transcript contains inappropriate content. Video should be blocked despite safe thumbnail.",
  "video_title": "Adult Comedy Special",
  "channel_title": "Comedy Central"
}
```

### Example 3: Safe Transcript, Unsafe Thumbnail

```json
{
  "is_safe_transcript": true,
  "is_safe_thumbnail": false,
  "is_safe": false,
  "transcript_reason": "Content is appropriate and educational for children.",
  "thumbnail_reason": "Thumbnail flagged as UNSAFE. Detected: adult, racy.",
  "overall_reason": "‚ùå UNSAFE: Thumbnail contains inappropriate imagery. Video should be blocked despite safe transcript.",
  "video_title": "Clickbait Video Title",
  "channel_title": "Viral Content Channel"
}
```

### Example 4: Both Unsafe

```json
{
  "is_safe_transcript": false,
  "is_safe_thumbnail": false,
  "is_safe": false,
  "transcript_reason": "UNSAFE - Contains violence and inappropriate themes.",
  "thumbnail_reason": "Thumbnail flagged as UNSAFE. Detected: violence.",
  "overall_reason": "‚ùå UNSAFE: Both transcript and thumbnail contain inappropriate content. Video should be blocked.",
  "video_title": "Inappropriate Video",
  "channel_title": "Adult Channel"
}
```

---

## üö® Error Responses

### 400 Bad Request - Empty URL

```json
{
  "detail": "video_url cannot be empty"
}
```

### 400 Bad Request - Invalid URL

```json
{
  "detail": "video_url must be a YouTube URL (youtube.com, youtu.be, youtube.com/shorts)"
}
```

### 400 Bad Request - Invalid Video ID

```json
{
  "detail": "Invalid YouTube URL: Could not extract video ID from URL"
}
```

### 500 Internal Server Error - Transcript Analysis Failed

```json
{
  "detail": "Video transcript analysis failed: Video not found"
}
```

### 500 Internal Server Error - Thumbnail Failed

```json
{
  "detail": "Thumbnail moderation failed: Failed to download image"
}
```

---

## üíª Usage Examples

### cURL

```bash
curl -X POST "http://localhost:8000/api/happyScroll/v1/verdict" \
  -H "Content-Type: application/json" \
  -d '{
    "video_url": "https://www.youtube.com/watch?v=dQw4w9WgXcQ"
  }'
```

### Python

```python
import requests

response = requests.post(
    "http://localhost:8000/api/happyScroll/v1/verdict",
    json={"video_url": "https://www.youtube.com/watch?v=dQw4w9WgXcQ"},
    timeout=60
)

verdict = response.json()

if verdict["is_safe"]:
    print(f"‚úÖ SAFE: {verdict['overall_reason']}")
else:
    print(f"‚ùå UNSAFE: {verdict['overall_reason']}")
```

### JavaScript (Browser Extension)

```javascript
async function checkVideo(youtubeUrl) {
  try {
    const response = await fetch('http://localhost:8000/api/happyScroll/v1/verdict', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ video_url: youtubeUrl })
    });
    
    const verdict = await response.json();
    
    if (verdict.is_safe) {
      console.log(`‚úÖ Video is safe: ${verdict.video_title}`);
      return true;
    } else {
      console.log(`‚ùå Video is unsafe: ${verdict.overall_reason}`);
      // Hide or blur video
      return false;
    }
  } catch (error) {
    console.error('Error checking video:', error);
    return false; // Fail-safe: block on error
  }
}
```

### React Component

```javascript
import { useState } from 'react';

function VideoSafetyChecker() {
  const [verdict, setVerdict] = useState(null);
  const [loading, setLoading] = useState(false);

  const checkVideo = async (videoUrl) => {
    setLoading(true);
    try {
      const response = await fetch('http://localhost:8000/api/happyScroll/v1/verdict', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ video_url: videoUrl })
      });
      
      const data = await response.json();
      setVerdict(data);
    } catch (error) {
      console.error('Error:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      {loading && <p>Analyzing video...</p>}
      {verdict && (
        <div className={verdict.is_safe ? 'safe' : 'unsafe'}>
          <h3>{verdict.is_safe ? '‚úÖ Safe' : '‚ùå Unsafe'}</h3>
          <p>{verdict.overall_reason}</p>
          <p>Video: {verdict.video_title}</p>
          <p>Channel: {verdict.channel_title}</p>
        </div>
      )}
    </div>
  );
}
```

---

## ‚è±Ô∏è Performance

### With Parallel Processing (Current Implementation)

| Operation | Time | Notes |
|-----------|------|-------|
| Transcript Analysis | 15-30 seconds | Longest operation |
| Thumbnail Moderation | 2-5 seconds | Runs in parallel |
| Result Combination | <1 second | After both complete |
| **Total Request Time** | **15-30 seconds** | ‚ö° Only as long as the slowest task! |

### Before Parallel Processing (Sequential)
- Total Time: 20-35 seconds
- Improvement: **30-40% faster** with parallel processing

**Note**: 
- First request may take longer due to cold start
- Response time is determined by the longest operation (transcript analysis)
- Thumbnail analysis completes while transcript is still processing

---

## üõ°Ô∏è Safety Rules

### Transcript Analysis (12 Strict Rules)

The Gemini AI analysis checks for:

1. ‚ùå **Nudity** - Any form (partial, full, artistic, medical, accidental)
2. ‚ùå **Sexual Content** - References, innuendos, jokes, gestures
3. ‚ùå **Racism** - Any form (jokes, stereotypes, slurs)
4. ‚ùå **Discrimination** - Religion, caste, gender, region, color
5. ‚ùå **Violence** - Physical harm, weapons, blood, fighting
6. ‚ùå **Abusive Language** - Swear words, profanity, insults
7. ‚ùå **Drugs/Alcohol** - Any references or depiction
8. ‚ùå **Scary Content** - Horror, gore, disturbing imagery
9. ‚ùå **Inappropriate Gestures** - Offensive signs, provocative movements
10. ‚ùå **Adult Themes** - Dating, romance, intimate situations
11. ‚ùå **Dangerous Acts** - Stunts, risky behavior
12. ‚ùå **Religious Insensitivity** - Mocking any faith

### Thumbnail Moderation (5 Categories)

Google Cloud Vision SafeSearch checks:

1. **Adult** - Adult content, nudity
2. **Violence** - Violent or bloody content
3. **Racy** - Suggestive or provocative content
4. **Medical** - Medical or surgical content
5. **Spoof** - Fake or manipulated content

---

## üîÑ Comparison with Individual Endpoints

### Individual API Calls (Old Way)

```python
# Two separate requests
transcript = requests.post("/api/analyze_video", json={"video_url": url})
thumbnail = requests.post("/api/moderate", json={"youtube_url": url})

# Manual combination
is_safe = transcript.json()["is_safe"] and thumbnail.json()["safe"]
```

### Combined Endpoint (New Way)

```python
# Single request
verdict = requests.post("/api/happyScroll/v1/verdict", json={"video_url": url})

# Everything in one response
is_safe = verdict.json()["is_safe"]
```

**Benefits:**
- ‚úÖ Single API call instead of two
- ‚úÖ Automatic result combination
- ‚úÖ Consistent response format
- ‚úÖ Better error handling
- ‚úÖ Comprehensive logging

---

## üß™ Testing

Run the test suite:

```bash
python test_happyscroll_verdict.py
```

This will test:
- ‚úÖ Safe videos
- ‚úÖ Unsafe videos
- ‚úÖ Error cases
- ‚úÖ Various URL formats
- ‚úÖ Comparison with individual endpoints

---

## üìñ API Documentation

Interactive documentation available at:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## üéØ Use Cases

### 1. Parental Control Browser Extension

```javascript
// Check video before allowing playback
chrome.webNavigation.onBeforeNavigate.addListener(async (details) => {
  if (isYouTubeVideo(details.url)) {
    const verdict = await checkVideoVerdict(details.url);
    if (!verdict.is_safe) {
      chrome.tabs.update(details.tabId, { url: 'blocked.html' });
    }
  }
});
```

### 2. Kids' Video Platform

```python
def moderate_video_submission(video_url):
    verdict = get_verdict(video_url)
    
    if verdict["is_safe"]:
        # Approve video for kids platform
        approve_video(video_url, verdict["video_title"])
    else:
        # Reject video
        reject_video(
            video_url,
            reason=verdict["overall_reason"]
        )
```

### 3. YouTube Content Filter

```javascript
// Filter YouTube feed in real-time
async function filterYouTubeFeed() {
  const videos = document.querySelectorAll('ytd-video-renderer');
  
  for (const video of videos) {
    const url = video.querySelector('a').href;
    const verdict = await getVerdict(url);
    
    if (!verdict.is_safe) {
      video.style.display = 'none';
      console.log(`Blocked: ${verdict.video_title}`);
    }
  }
}
```

---

## ‚öôÔ∏è Configuration

Required environment variables (already configured in `.env`):

```properties
YOUTUBE_API_KEY=your_youtube_api_key
GEMINI_API_KEY=your_gemini_api_key
GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json
GOOGLE_CLOUD_PROJECT=your_project_id
SAFETY_THRESHOLD=POSSIBLE
```

---

## üöÄ Deployment

The endpoint is production-ready and includes:

- ‚úÖ Comprehensive error handling
- ‚úÖ Detailed logging
- ‚úÖ Input validation
- ‚úÖ Timeout handling
- ‚úÖ CORS support
- ‚úÖ Clear response format

---

## üìä API Quotas

### YouTube Data API
- **Daily Quota**: 10,000 units
- **Per Request**: ~1 unit
- **Daily Capacity**: ~10,000 verdicts/day

### Google Cloud Vision
- **Free Tier**: 1,000 requests/month
- **Paid Tier**: $1.50 per 1,000 requests

### Gemini AI
- **Free Tier**: 60 requests/minute
- **Sufficient** for most use cases

---

## üîß Troubleshooting

### Issue: Request timeout
**Solution**: Increase timeout to 60 seconds. First request may take longer.

### Issue: "YouTube API key not configured"
**Solution**: Add `YOUTUBE_API_KEY` to `.env` file

### Issue: "Video not found"
**Solution**: Ensure video is public and URL is correct

### Issue: Slow performance
**Solution**: 
- Normal processing time is 20-35 seconds
- Consider caching results by video ID
- Implement queue system for batch processing

---

## üìà Future Enhancements

1. **Caching** - Cache results by video ID for faster repeated checks
2. **Webhooks** - Async processing with callback URL
3. **Batch Processing** - Analyze multiple videos in one request
4. **Video Sampling** - Analyze video frames at intervals
5. **Comments Analysis** - Include comment moderation

---

## ‚úÖ Summary

**Endpoint**: `POST /api/happyScroll/v1/verdict`

**What it does**:
- ‚úÖ Analyzes video transcript with Gemini AI
- ‚úÖ Analyzes video thumbnail with Google Vision
- ‚úÖ Combines results into single verdict
- ‚úÖ Returns comprehensive safety assessment

**Response**:
- `is_safe`: Overall verdict (both must be safe)
- `is_safe_transcript`: Transcript analysis result
- `is_safe_thumbnail`: Thumbnail moderation result
- Detailed reasons for each check

**Perfect for**:
- Parental control apps
- Browser extensions
- Content moderation platforms
- Kids' video platforms

---

**API Version**: 1.0
**Last Updated**: November 17, 2025
**Status**: ‚úÖ Production Ready
